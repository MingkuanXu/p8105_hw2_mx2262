---
title: "P8130 - Homework 2"
author: "Mingkuan Xu"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r } 
library(tidyverse)
```

## Problem 1

#### Part A - The Mr. Trash Wheel sheet
Load trash wheel data, remove useless columns and take a quick look.
```{r results=FALSE,message=FALSE}
trash_wheel_data = 
  readxl::read_excel(
    path="data/Trash-Wheel-Collection-Totals-7-2020-2.xlsx",
    sheet="Mr. Trash Wheel",
    skip=1) %>%
  janitor::clean_names()
skimr::skim(trash_wheel_data)
```
We find useless columns x15, x16, and x17; remove them. Also we omit rows that do not include dumpster-specific data as instructed. Finally we round the number of sports balls to the nearest integer as instructed.

```{r}
trash_wheel_data = 
  select(trash_wheel_data,-x15,-x16,-x17) %>% 
  drop_na(dumpster) %>%
  mutate(sports_balls = round(sports_balls))

head(trash_wheel_data)
```

#### Part B - Precipitation data for 2018 and 2019

We read the precipitation data for 2018 & 2019, drop useless rows, and bind them together.
```{r}
precipitation_2018_data = 
  readxl::read_excel(
    path="data/Trash-Wheel-Collection-Totals-7-2020-2.xlsx",
    sheet="2018 Precipitation",
    skip=1) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year=2018) %>%
  relocate(year)

precipitation_2019_data = 
  readxl::read_excel(
    path="data/Trash-Wheel-Collection-Totals-7-2020-2.xlsx",
    sheet="2019 Precipitation",
    skip=1) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year=2019) %>%
  relocate(year)

precipitation_data = 
  bind_rows(precipitation_2018_data,precipitation_2019_data) %>%
  mutate(month = month.name[month])

head(precipitation_data)
```

#### Part C - Summary
For the dumpster data, the information of `r nrow(trash_wheel_data)` dumpsters were recorded, including the number of `r select(trash_wheel_data,plastic_bottles:sports_balls) %>% janitor::clean_names(case="sentence") %>% names() %>% tolower()` they contained. The average weight is `r mean(pull(trash_wheel_data,weight_tons))` tons; the average volume is `r mean(pull(trash_wheel_data,volume_cubic_yards))` cubic yards. Specifically, the median number of sports balls in a dumpster in 2019 is `r filter(trash_wheel_data, year==2019) %>% pull(sports_balls) %>% median()`.

For the precipitation data, we collected `r rename(precipitation_data,precipitation=total) %>% names()`. Over the `r nrow(precipitation_data)` months of collected data from years `r unique(precipitation_data$year)`, we observe a mean of `r mean(pull(precipitation_data,total))` inches and median of `r median(precipitation_data$total)` inches per month. The total precipitation for year 2018 is `r pull(filter(precipitation_data,year==2018),total) %>% sum()` inches; the total precipitation for year 2019 is `r pull(filter(precipitation_data,year==2019),total) %>% sum()` inches.

## Problem 2

#### Part A - Preprocess pols-month.csv

```{r}
pols_data = 
  read_csv(file = "data/pols-month.csv",show_col_types = FALSE) %>%
  separate(mon,c("year","month","day"),"-") %>% # Separate date info
  mutate(month = month.name[as.integer(month)]) %>% # Transform to month names
  mutate(president = ifelse(prez_dem==0,"gop","dem")) %>% # Create column president
  select(-day,-prez_dem,-prez_gop) # Remove useless columns

head(pols_data)
```
#### Part B - Preprocess snp.csv 
```{r}
snp_data = 
  read_csv(file = "data/snp.csv",show_col_types = FALSE) %>%
  separate(date,c("day","month","year"),"/") %>% # Separate date info
  mutate(month = month.name[as.integer(month)]) %>% # Transform to month names
  mutate(year = 
           ifelse(year>30,
                  paste("19",as.character(year),sep=""),
                  paste("20",as.character(year),sep=""))) %>% # Full year expression
  select(-day) %>% # Remove useless column
  relocate(year,month) %>% # Arrange columns properly
  rename(snp_close=close) # Rename column

head(snp_data)
```

#### Part C - Preprocess unemployment.csv

```{r}
unemploy_data = read_csv("data/unemployment.csv",show_col_types = FALSE) %>%
  pivot_longer(Jan:Dec,names_to = "month") %>% # Reshape the data
  mutate(month=month.name[match(month, month.abb)]) %>% # Change month abb to month name.
  rename(unemploy_rate=value,year=Year) %>% # Rename column
  mutate(year=as.character(year))
head(unemploy_data)
```

#### Part D - Merge data & describe

```{r}
full_data = left_join(pols_data,snp_data,by=c("year","month"))
full_data = left_join(full_data,unemploy_data,by=c("year","month"))
skimr::skim(full_data)
```

The pols dataframe contains `r nrow(pols_data)` observations of `r ncol(pols_data)` variables related to the number of national politicians who are democratic or republican in the range of years
(`r range(pull(pols_data,year)) `). 

The snp dataframe contains `r nrow(snp_data)` observations of `r ncol(snp_data)` variables related to Standard & Poorâ€™s stock market index (S&P), often used as a representative measure of stock market as a whole,in the range of years (`r range(pull(snp_data,year))`).

The unemployment dataframe contains `r nrow(unemploy_data)` observations of `r ncol(unemploy_data)` variables, representing the percentage of unemployment in each month in the range of years (`r range(pull(unemploy_data,year))`).

The resulting combined dataframe contains `r nrow(full_data)` observations of `r ncol(full_data)` variables. It summarized the information described in the three datasets: years, months, info of politicians (including the party of the president, the number of governovs, senators, and representatives), S&P indexes, and unemployment rates, in the range of years (`r range(pull(full_data,year))`).

## Problem 3

#### Part A - Preprocess data of child names
```{r}

names_data = read_csv(file="data/Popular_Baby_Names.csv") %>%
  distinct() %>% # Remove duplicate rows
  janitor::clean_names() %>%
  mutate(childs_first_name = tolower(childs_first_name))%>% # Change all names to lower cases.
  mutate(ethnicity = # Unify names of ethnicity
           ifelse(ethnicity=="ASIAN AND PACI",
                  "ASIAN AND PACIFIC ISLANDER",
                  ethnicity)) %>%
  mutate(ethnicity = 
           ifelse(ethnicity=="BLACK NON HISP",
                  "BLACK NON HISPANIC",
                  ethnicity)) %>%
  mutate(ethnicity = 
           ifelse(ethnicity=="WHITE NON HISP",
                  "WHITE NON HISPANIC",
                  ethnicity)) 
```

#### Part B - Tables for Olivia & most popular names

```{r}
olivia_data = 
  filter(names_data,childs_first_name=="olivia") %>% # Find rows
  select(-gender,-count,-childs_first_name) %>% # Remove useless columns
  pivot_wider(names_from = year_of_birth,values_from = rank) # Reshape

olivia_data

popular_male_data = 
  filter(names_data,rank==1) %>%
  filter(gender=="MALE") %>% # Find rows
  select(-gender,-count,-rank) %>% # Remove useless columns
  pivot_wider(names_from = year_of_birth,values_from = childs_first_name) # Reshape

popular_male_data
```

#### Part C - Scatter Plot

```{r}
white_male_2016_data = 
  filter(names_data,ethnicity=="WHITE NON HISPANIC",year_of_birth==2016,gender=="MALE") %>% 
  select(count,rank,name=childs_first_name)

ggplot(white_male_2016_data, aes(x=rank, y=count)) +
  geom_point() +
  xlab("Rank in Popularity") + 
  ylab("Number of Children")
```



